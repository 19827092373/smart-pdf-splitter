import streamlit as st
import os
import tempfile
import pandas as pd
import shutil
from pypdf import PdfReader
from core_logic import (
    convert_pdf_to_images,
    call_vision_api,
    parse_gemini_response,
    parse_openai_response,
    parse_anthropic_response,
    parse_qwen_response,
    parse_zhipu_response,
    split_pdf,
    create_zip
)

st.set_page_config(page_title="æ™ºèƒ½ PDF åˆ‡åˆ†å·¥å…· (Smart PDF Splitter)", layout="wide")

# Session State Initialization
if 'pdf_path' not in st.session_state:
    st.session_state.pdf_path = None
if 'current_filename' not in st.session_state:
    st.session_state.current_filename = None
if 'toc_data' not in st.session_state:
    st.session_state.toc_data = []
if 'preview_images' not in st.session_state:
    st.session_state.preview_images = []
if 'zip_buffer' not in st.session_state:
    st.session_state.zip_buffer = None

# Sidebar Configuration
with st.sidebar:
    # API Configuration in Expander for cleaner UI
    with st.expander("ğŸ”Œ API è¿æ¥è®¾ç½® (Connection Settings)", expanded=True):
        # Provider Selection
        provider_config = {
            "Google Gemini": {
                "base_url": "https://generativelanguage.googleapis.com",
                "api_key_label": "Gemini API Key",
                "api_key_help": "è¾“å…¥æ‚¨çš„ Google Gemini API Key",
                "models": [
                    "gemini-3-flash-preview",
                    "gemini-3-pro-preview",
                    "gemini-3-pro-image-preview",
                    "gemini-2.5-flash",
                    "gemini-2.5-flash-lite",
                    "gemini-2.5-pro",
                    "gemini-2.0-flash-exp",
                    "gemini-2.0-flash",
                    "gemini-1.5-pro",
                    "gemini-1.5-flash"
                ]
            },
            "OpenAI": {
                "base_url": "https://api.openai.com/v1",
                "api_key_label": "OpenAI API Key",
                "api_key_help": "è¾“å…¥æ‚¨çš„ OpenAI API Key (sk-...)",
                "models": [
                    "gpt-4.1",
                    "gpt-4.1-mini",
                    "gpt-4o",
                    "gpt-4o-mini",
                    "gpt-5.2",
                    "gpt-5-mini"
                ]
            },
            "Anthropic Claude": {
                "base_url": "https://api.anthropic.com",
                "api_key_label": "Claude API Key",
                "api_key_help": "è¾“å…¥æ‚¨çš„ Anthropic API Key (sk-ant-...)",
                "models": [
                    "claude-3-5-sonnet-20241022",
                    "claude-3-5-haiku-20241022",
                    "claude-3-opus-20240229",
                    "claude-3-sonnet-20240229",
                    "claude-3-haiku-20240307"
                ]
            },
            "æ™ºè°± AI (Zhipu AI)": {
                "base_url": "https://open.bigmodel.cn/api/paas/v4",
                "api_key_label": "æ™ºè°± API Key",
                "api_key_help": "è¾“å…¥æ‚¨çš„æ™ºè°± API Key",
                "models": [
                    "glm-4.6v",
                    "glm-4.6v-flashx",
                    "glm-4.6v-flash",
                    "glm-4v",
                    "glm-4v-plus"
                ]
            },
            "é˜¿é‡Œé€šä¹‰åƒé—® (Qwen)": {
                "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
                "api_key_label": "DashScope API Key",
                "api_key_help": "è¾“å…¥æ‚¨çš„é˜¿é‡Œäº‘ DashScope API Key (sk-...)",
                "models": [
                    "qwen-vl-max",
                    "qwen-vl-plus",
                    "qwen-vl-v1",
                    "qwen2.5-vl-72b-instruct"
                ]
            },
            "DeepSeek": {
                "base_url": "https://api.deepseek.com/v1",
                "api_key_label": "DeepSeek API Key",
                "api_key_help": "è¾“å…¥æ‚¨çš„ DeepSeek API Key (sk-...)",
                "models": [
                    "deepseek-chat",
                    "deepseek-coder",
                    "deepseek-r1"
                ]
            }
        }

        provider_names = list(provider_config.keys())
        selected_provider = st.selectbox("æ¨¡å‹æä¾›å•† (Provider)", options=provider_names, index=0)

        # Get config for selected provider
        config = provider_config[selected_provider]
        default_base_url = config["base_url"]

        api_key = st.text_input(
            config["api_key_label"],
            type="password",
            help=config["api_key_help"]
        )
        base_url = st.text_input(
            "Base URL",
            value=default_base_url,
            help="API åŸºç¡€åœ°å€ (å¦‚æœä½¿ç”¨ä¸­è½¬æœåŠ¡è¯·ä¿®æ”¹æ­¤å¤„)"
        )

        # Provider-specific warnings
        if selected_provider == "Google Gemini" and api_key and api_key.startswith("sk-") and "googleapis.com" in base_url:
            st.warning("âš ï¸ æ£€æµ‹åˆ° 'sk-' å¼€å¤´çš„ Keyï¼Œè¯·åŠ¡å¿…å°† Base URL ä¿®æ”¹ä¸ºæœåŠ¡å•†æä¾›çš„åœ°å€ï¼")

        # Model Selection based on provider
        model_options = config["models"]
        selected_model = st.selectbox(
            "æ¨¡å‹é€‰æ‹© (Model)",
            options=model_options + ["è‡ªå®šä¹‰..."],
            index=0
        )

        if selected_model == "è‡ªå®šä¹‰...":
            if selected_provider == "Google Gemini":
                default_custom = "gemini-2.5-flash"
            elif selected_provider == "OpenAI":
                default_custom = "gpt-4o"
            elif selected_provider == "Anthropic Claude":
                default_custom = "claude-3-5-sonnet-20241022"
            elif selected_provider == "æ™ºè°± AI (Zhipu AI)":
                default_custom = "glm-4.6v"
            elif selected_provider == "é˜¿é‡Œé€šä¹‰åƒé—® (Qwen)":
                default_custom = "qwen-vl-plus"
            else:
                default_custom = "custom-model"
            model_name = st.text_input("è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°", value=default_custom)
        else:
            model_name = selected_model
    
    st.markdown("---")
    st.markdown("**ä½¿ç”¨è¯´æ˜:**")
    st.markdown("1. ä¸Šä¼ æ‰«æç‰ˆ PDF")
    st.markdown("2. æŸ¥çœ‹é¢„è§ˆï¼Œç¡®è®¤ç›®å½•é¡µèŒƒå›´")
    st.markdown("3. è®¾ç½®æ­£æ–‡åç§»é‡")
    st.markdown("4. AI è¯†åˆ«ç›®å½•")
    st.markdown("5. æ ¡å¯¹å¹¶åˆ‡åˆ†ä¸‹è½½")

# Step 1: File Upload
uploaded_file = st.file_uploader("ä¸Šä¼  PDF æ–‡ä»¶ (Upload PDF)", type=["pdf"])

if uploaded_file:
    # Check if file has changed using the original filename
    if st.session_state.current_filename != uploaded_file.name:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            st.session_state.pdf_path = tmp_file.name
        
        st.session_state.current_filename = uploaded_file.name
        st.success(f"æ–‡ä»¶å·²ä¸Šä¼ : {uploaded_file.name}")
        
        # Clear previous state ONLY when file changes
        st.session_state.toc_data = []
        st.session_state.preview_images = []
        st.session_state.zip_buffer = None
        st.session_state.final_toc = None # Clear toc data as well

    # Preview Section
    st.subheader("1. é¢„è§ˆä¸å®šä½ (Preview & Scoping)")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.info("è¯·æŸ¥çœ‹å³ä¾§é¢„è§ˆå›¾ï¼Œç¡®å®šç›®å½•æ‰€åœ¨çš„é¡µç èŒƒå›´ã€‚")
        toc_start = st.number_input("ç›®å½•èµ·å§‹é¡µ (PDFé¡µç )", min_value=1, value=3)
        toc_end = st.number_input("ç›®å½•ç»“æŸé¡µ (PDFé¡µç )", min_value=1, value=5)
        
        preview_btn = st.button("ç”Ÿæˆé¢„è§ˆå›¾ (Generate Preview)")
        
    with col2:
        if preview_btn and st.session_state.pdf_path:
            with st.spinner("æ­£åœ¨ç”Ÿæˆé¢„è§ˆ..."):
                # Preview a range covering likely TOC and start of content
                images = convert_pdf_to_images(st.session_state.pdf_path, 1, 10)
                st.session_state.preview_images = images
        
        if st.session_state.preview_images:
            st.write("PDF å‰ 10 é¡µé¢„è§ˆ:")
            img_cols = st.columns(5)
            for i, img in enumerate(st.session_state.preview_images):
                with img_cols[i % 5]:
                    st.image(img, caption=f"Page {i+1}", width='stretch')

    st.markdown("---")

    # Step 2: Offset Configuration & AI Analysis
    st.subheader("2. AI è¯†åˆ«ä¸æ ¡å¯¹ (Analysis & Review)")
    
    col_input, col_action = st.columns([2, 1])
    
    with col_input:
        offset_ref_book_page = st.number_input("å‚è€ƒï¼šæ­£æ–‡ç¬¬ 1 è¯¾åœ¨ä¹¦ä¸Šçš„é¡µç  (é€šå¸¸æ˜¯ 1)", value=1)
        offset_ref_pdf_page = st.number_input("å¯¹åº” PDF çš„å®é™…é¡µç  (è¯·çœ‹é¢„è§ˆå›¾)", value=7)
        
        # Calculate offset: PDF_Page = Book_Page + Offset
        # Offset = PDF_Page - Book_Page
        calculated_offset = offset_ref_pdf_page - offset_ref_book_page
        st.caption(f"å½“å‰è®¡ç®—çš„é¡µç åç§»é‡ (Offset): **{calculated_offset}** (PDFé¡µç  = ä¹¦æœ¬é¡µç  + {calculated_offset})")

    with col_action:
        st.write("") # Spacer
        st.write("") 
        analyze_btn = st.button("ğŸ¤– å¼€å§‹ AI è¯†åˆ«ç›®å½•", type="primary")

    if analyze_btn:
        if not api_key:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ API Key")
        else:
            with st.spinner(f"æ­£åœ¨è¯·æ±‚ {selected_provider} API åˆ†æç›®å½•... (è¿™å¯èƒ½éœ€è¦åå‡ ç§’)"):
                toc_images = convert_pdf_to_images(st.session_state.pdf_path, toc_start, toc_end)

                prompt = """
You are a sophisticated document structure parser specializing in Table of Contents (TOC) extraction.

### GOAL
Extract a structured list of lessons/sections from the provided images for the purpose of splitting a PDF book.

### CORE REASONING & EXTRACTION RULES
1. **Hierarchical Context (CRITICAL)**:
   - You must scan the text linearly.
   - Always track the **Current Chapter** (e.g., "ç¬¬åäº”ç« ", "Chapter 1", "Unit 3").
   - When you encounter a **Section/Lesson** (e.g., "ä¸€ã€ç”µèƒ½", "Section 1", "1.1"), you MUST combine it with the **Current Chapter** info to create a unique title.

2. **Naming Convention (Unique & Descriptive)**:
   - **Standard Format**: `[Chapter Number/ID].[Section Number/ID] [Title]`
   - **Example**:
     - If Chapter is "ç¬¬åäº”ç« " (15) and Section is "ä¸€ã€ç”µèƒ½" (1), Output Title: **"15.1 ç”µèƒ½"**
     - If Chapter is "Unit 1" and Section is "Reading", Output Title: **"Unit 1 - Reading"**
   - **Fallback**: If there is no clear chapter number, use the Section Title as is.

3. **Constraint - Uniqueness**:
   - Ensure every generated title is unique. If two sections have the exact same name, append the page number or parent chapter to distinguish them.

4. **Target Content**:
   - Extract ONLY entries that point to a specific starting page number.
   - Ignore structural placeholders that do not correspond to actual content pages (unless they are the content itself).

### OUTPUT FORMAT
Return ONLY a raw JSON array of objects. No markdown formatting.
[
    {"title": "15.1 ç”µèƒ½", "page": 2},
    {"title": "15.2 ç”µåŠŸç‡", "page": 6},
    {"title": "é™„å½• è¯æ±‡è¡¨", "page": 105}
]
"""

                response = call_vision_api(selected_provider, api_key, base_url, model_name, toc_images, prompt)

                if "error" in response:
                    st.error(f"API Error: {response['error']}")
                    st.json(response)
                else:
                    # Parse response based on provider
                    if selected_provider == "Google Gemini":
                        parsed_data = parse_gemini_response(response)
                    elif selected_provider == "OpenAI":
                        parsed_data = parse_openai_response(response)
                    elif selected_provider == "Anthropic Claude":
                        parsed_data = parse_anthropic_response(response)
                    elif selected_provider == "æ™ºè°± AI (Zhipu AI)":
                        parsed_data = parse_zhipu_response(response)
                    elif selected_provider == "é˜¿é‡Œé€šä¹‰åƒé—® (Qwen)":
                        parsed_data = parse_qwen_response(response)
                    else:
                        # Default to OpenAI format for DeepSeek and others
                        parsed_data = parse_openai_response(response)

                    if parsed_data:
                        st.session_state.toc_data = parsed_data
                        st.success(f"æˆåŠŸè¯†åˆ« {len(parsed_data)} ä¸ªç« èŠ‚ï¼")
                    else:
                        st.error("æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„ JSON æ•°æ®ã€‚è¯·é‡è¯•æˆ–æ£€æŸ¥ API å“åº”ã€‚")
                        st.json(response)

    # Data Editor
    if st.session_state.toc_data:
        st.info("è¯·åœ¨ä¸‹æ–¹è¡¨æ ¼ä¸­æ ¡å¯¹è¯†åˆ«ç»“æœã€‚æ‚¨å¯ä»¥ç›´æ¥ä¿®æ”¹æ ‡é¢˜ã€é¡µç ï¼Œæˆ–æ·»åŠ /åˆ é™¤è¡Œã€‚")
        
        # Convert to DataFrame for editing
        df = pd.DataFrame(st.session_state.toc_data)
        
        # Add calculated columns for reference
        if 'page' in df.columns:
            df['pdf_start_page'] = df['page'] + calculated_offset
        
        edited_df = st.data_editor(
            df,
            num_rows="dynamic",
            width='stretch',
            column_config={
                "title": "ç« èŠ‚æ ‡é¢˜",
                "page": "ä¹¦æœ¬é¡µç ",
                "pdf_start_page": "PDFèµ·å§‹é¡µ (é¢„è§ˆ)"
            }
        )
        
        st.session_state.final_toc = edited_df.to_dict('records')

        st.markdown("---")
        
        # Step 3: Split Preview & Execution
        st.subheader("3. åˆ‡åˆ†é¢„è§ˆä¸æ‰§è¡Œ (Preview & Execute)")
        
        # Get PDF info for validation
        try:
            reader = PdfReader(st.session_state.pdf_path)
            total_pdf_pages = len(reader.pages)
            st.info(f"ğŸ“„ å½“å‰ PDF æ€»é¡µæ•°: **{total_pdf_pages}**")
        except Exception as e:
            st.error("æ— æ³•è¯»å– PDF é¡µæ•°ï¼Œæ–‡ä»¶å¯èƒ½æŸåã€‚")
            total_pdf_pages = 0

        # Generate Split Plan Preview
        preview_data = []
        is_valid_plan = True
        
        if st.session_state.final_toc:
            sorted_chapters = sorted(st.session_state.final_toc, key=lambda x: int(x['page']) if str(x['page']).isdigit() else 0)
            
            for i, chapter in enumerate(sorted_chapters):
                try:
                    start_book = int(chapter['page'])
                except:
                    start_book = 0
                    
                # Calculate PDF Page Index (1-based for display)
                start_pdf = start_book + calculated_offset
                
                # Determine End Page
                if i < len(sorted_chapters) - 1:
                    try:
                        end_book = int(sorted_chapters[i+1]['page'])
                    except:
                        end_book = start_book
                    end_pdf = end_book + calculated_offset - 1
                else:
                    end_pdf = total_pdf_pages
                
                status = "âœ… æ­£å¸¸"
                if start_pdf > total_pdf_pages:
                    status = "âŒ è¶…å‡ºèŒƒå›´ (èµ·å§‹é¡µ > æ€»é¡µæ•°)"
                    is_valid_plan = False
                elif start_pdf > end_pdf:
                     status = "âš ï¸ èŒƒå›´é”™è¯¯ (èµ·å§‹ > ç»“æŸ)"
                     # This might happen if chapters are out of order
                
                preview_data.append({
                    "ç« èŠ‚æ ‡é¢˜": chapter['title'],
                    "PDF èµ·å§‹é¡µ": start_pdf,
                    "PDF ç»“æŸé¡µ": end_pdf,
                    "çŠ¶æ€": status
                })
            
            st.table(pd.DataFrame(preview_data))

            if not is_valid_plan:
                st.error("âŒ æ£€æµ‹åˆ°é¡µç è¶…å‡ºèŒƒå›´ï¼è¯·å›åˆ°ä¸Šé¢çš„ '2. AI è¯†åˆ«ä¸æ ¡å¯¹' åŒºåŸŸï¼Œå‡å° 'PDF å®é™…é¡µç ' çš„æ•°å€¼ï¼Œæˆ–è€…æ£€æŸ¥è¡¨æ ¼ä¸­çš„é¡µç æ˜¯å¦æ­£ç¡®ã€‚")
            else:
                if st.button("âœ‚ï¸ å¼€å§‹åˆ‡åˆ† PDF", type="primary"):
                    with st.spinner("æ­£åœ¨åˆ‡åˆ† PDF..."):
                        with tempfile.TemporaryDirectory() as temp_out_dir:
                            files = split_pdf(
                                st.session_state.pdf_path, 
                                st.session_state.final_toc, 
                                calculated_offset, 
                                temp_out_dir
                            )
                            
                            if files:
                                # Create ZIP and store in session state
                                zip_buffer = create_zip(files, "split_files.zip")
                                st.session_state.zip_buffer = zip_buffer
                                st.success(f"âœ… åˆ‡åˆ†æˆåŠŸï¼å…±ç”Ÿæˆ {len(files)} ä¸ªæ–‡ä»¶ã€‚è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸‹è½½ã€‚")
                            else:
                                st.warning("æ²¡æœ‰ç”Ÿæˆä»»ä½•æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥é¡µç èŒƒå›´æ˜¯å¦è¶…å‡ºäº† PDF æ€»é¡µæ•°ã€‚")
                
                # Show Download Button if buffer exists
                if st.session_state.zip_buffer:
                    st.download_button(
                        label="â¬‡ï¸ ç‚¹å‡»ä¸‹è½½åˆ‡åˆ†å¥½çš„æ–‡ä»¶åŒ… (ZIP)",
                        data=st.session_state.zip_buffer.getvalue(),
                        file_name="split_pdf_files.zip",
                        mime="application/zip",
                        width='stretch'
                    )
else:
    st.info("ğŸ‘‹ è¯·å…ˆä¸Šä¼ ä¸€ä¸ª PDF æ–‡ä»¶å¼€å§‹ã€‚")
